---
title: "N-Pact Factor assessment for IRAP research"
author: "Ian Hussey"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: hide
    highlight: haddock
    theme: flatly
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(message = FALSE, 
                      warning = FALSE)

```

# Dependencies

```{r}

library(pwr)
library(tidyverse)
library(janitor)
library(viridis)
library(knitr)
library(kableExtra)
library(bayestestR)
library(scales)
library(sjPlot)
library(performance)

# create directory for plots
dir.create("plots")

```

# Data

```{r}

data_combined <- read_csv("../data/processed/data_fraley_and_irap.csv") |>
  # clean names and values
  rename(N = n_participants_after_exclusions,
         design = study_design_ignoring_trial_type_comparisons) |>
  mutate(year = str_replace(publication_year, "20", "'"),
         field = ifelse(journal == "IRAP", "IRAP research", "Social Psychology"),
         design = case_when(design == "b" ~ "between",
                            design == "w" ~ "within",
                            design == "m" ~ "mixed"),
         reported_n = !is.na(N))

```

# Descriptives

## IRAP studies

```{r}

# subset data
data_irap_n <- data_combined |>
  filter(journal == "IRAP") 

# calculate k articles
k_articles <- data_irap_n |>
  distinct(key) |>
  count() |>
  pull(n)

# calculate k studies
k_studies <- data_irap_n |>
  count()  |>
  pull(n)

# table
data_irap_n |>         
  summarize(`Total articles` = k_articles,
            `Total studies` = k_studies) |>
  kable() |>
  kable_classic(full_width = FALSE)

```

## Social and Personality Psychology studies

```{r}

data_combined_comparison <- data_combined |>
  filter(
    # filters for social and personality psych studies 
    # filter out non-social studies published in psych science
    (design == "between" & ((journal == "PS:S" & (social_ps == 1 | is.na(social_ps))) | journal != "PS:S")) |
      # filters for irap studies
      (journal == "IRAP" & design %in% c("between", "mixed") & used_inferential_statistics == TRUE) 
  ) |>
  filter(reported_n == TRUE)
  

data_combined_comparison |>
  filter(field != "IRAP research") |>
  count() |>
  kable() |>
  kable_classic(full_width = FALSE)

data_combined_comparison |>
  filter(field != "IRAP research") |>
  count(journal) |>
  kable() |>
  kable_classic(full_width = FALSE)

```

# Prevalence of NHST in the IRAP literature

Using the full sample

```{r}

# table by use of inferential stats
data_irap_n |>   
  count(`Reported N` = reported_n, 
        `Studies using inferential statistics` = used_inferential_statistics) |>
  mutate(percent = janitor::round_half_up(n/sum(n)*100, 1)) |>
  kable() |>
  kable_classic(full_width = FALSE)

```

# IRAP N per sample

All analyses from here are based on IRAP publications that employed NHST. 

## Descriptives

```{r}

# subset data. reused again further below
data_combined_using_nhst <- data_combined |>
  filter(used_inferential_statistics == TRUE & 
           reported_n == TRUE)

# subset further
data_irap_n_using_nhst <- data_combined_using_nhst |>
  filter(journal == "IRAP") 

# count articles
k_articles <- data_irap_n_using_nhst |>
  distinct(key) |>
  count() |>
  pull(n)

# count studies
k_studies <- data_irap_n_using_nhst |>
  count()  |>
  pull(n)

# calculate maximum a posteriori estimate (mode of a continuous variable) 
MAP <- bayestestR::map_estimate(data_irap_n_using_nhst$N) |>
  janitor::round_half_up(1) |>
  as.numeric()

# combine table
data_irap_n_using_nhst |>         
  summarize(`Total articles` = k_articles,
            `Total studies` = k_studies,
            `Total N` = sum(N),
            Median = median(N),
            MAD = janitor::round_half_up(mad(N), 1),
            Min = min(N),
            Max = max(N)) |>
  mutate(MAP = MAP) |>
  select(`Total articles`,
         `Total studies`,
         `Total N`,
         `MAP N` = MAP,
         `Median N` = Median,
         `MAD N` = MAD,
         `Min N` = Min,
         `Max N` = Max) |>
  kable() |>
  kable_classic(full_width = FALSE)

# plot
p_distribution <- 
  ggplot(data_irap_n_using_nhst, aes(N)) +
  geom_histogram(binwidth = 10) +
  theme_classic() +
  ylab("Count of studies") +
  xlab("Sample size (N)") +
  scale_x_continuous(breaks = seq(from = 0, to = 250, by = 10))

p_distribution

ggsave("plots/p_distribution.pdf",
       plot = p_distribution,
       width = 6,
       height = 4,
       units = "in")

```

## Split by study design

Note that IRAP publications with mixed designs also report results from between groups analyses, and so both mixed and between are included in the power analyses further sections below.

```{r}

data_combined_using_nhst |>
  distinct(title, design) |>
  count(design) |>
  mutate(percent = janitor::round_half_up(n/sum(n)*100, 1)) |>
  kable() |>
  kable_classic(full_width = FALSE)

```

## Change over time

### Table

```{r}

# subset irap data 
data_table_1_filtered <- data_combined_using_nhst |>
  filter(field == "IRAP research")

# calculate median N for each field and year
# round using typical half-up rule and not R's weird rounding
data_table_1_n_long <- data_table_1_filtered |>
  group_by(field, year) |>
  summarize(median_n = janitor::round_half_up(median(N, na.rm = TRUE), 0)) |>
  ungroup()

# Calculate median median n for each field
data_table_1_n_aggregate <- data_table_1_n_long |>
  group_by(field) |>
  summarize(median_median_n = median(median_n, na.rm = TRUE)) |>
  ungroup()

# Calculate k studies used to calculate median ns
data_table_1_k_long <- data_table_1_filtered |>
  count(field, year, name = "k_studies")

# combine Ns and Ks, reshape, and order field column by aggregate median median n 
data_table_1 <- 
  full_join(data_table_1_n_long, data_table_1_k_long, by = c("field", "year")) |>
  mutate(result = paste0(median_n, " (", k_studies, ")")) |>
  select(-median_n, -k_studies) |>
  pivot_wider(names_from = year, 
              values_from = result) |>
              #names_prefix = "NF ") |>
  left_join(data_table_1_n_aggregate, by = "field") |>
  mutate(field = fct_reorder(field, median_median_n)) |>
  arrange(desc(field)) |>
  select(field, median_median_n, 
         `'06`, `'07`, `'08`, `'09`, `'10`, `'11`, 
         `'12`, `'13`, `'14`, `'15`, `'16`, `'17`, 
         `'18`, `'19`, `'20`, `'21`, `'22`)

# print table
data_table_1 |>
  select(field, 
         Aggregate = median_median_n, 
         starts_with("'")) |>
         #starts_with("NF")) |>
  kable() |>
  kable_classic(full_width = FALSE)

```

### Figure

```{r}

# Filter out non-social studies published in psych science
# calculate median Ns
# order field column by same used in Table 1
data_figure_1 <- data_table_1_filtered |>
  group_by(field, year) |>
  summarize(median_n = janitor::round_half_up(median(N, na.rm = TRUE), 0)) |>
  ungroup() |>
  mutate(field = fct_rev(fct_relevel(field, levels(data_table_1$field))))

# plot 
ggplot(data_figure_1, aes(as.factor(year), median_n, group = field)) +
  geom_smooth(method = "lm", alpha = 0.2) +
  geom_line() +
  geom_point() +
  scale_color_viridis_d(option = "plasma", begin = 0.1, end = 0.9) +
  theme_classic() +
  ylab("Median sample size (N) per study") +
  xlab("Year") 

```

### Estimate change in median N over time

```{r fig.height=10, fig.width=6}

data_for_model_1 <- data_figure_1 |>
  mutate(year = as.numeric(str_remove(year, "'")),
         year_recentered = year - 06)

fit_1 <- lm(formula = median_n ~ year_recentered,
                data = data_for_model_1)

#check_model(fit_1)
#check_normality(fit_1)

tab_model(fit_1, 
          string.est = "B",
          digits = 1,
          ci.hyphen = ", ")

```

# IRAP N per group

## Median sample size 

### Table

```{r}

# Filter out non-social studies published in psych science
data_table_2_filtered <- data_combined_using_nhst |>
  filter(journal == "IRAP" & design %in% c("between", "mixed")) |>
  mutate(N_per_cell = N/n_groups_between)

# calculate median N for each field and year
# round using typical half-up rule and not R's weird rounding
data_table_2_n_long <- data_table_2_filtered |>
  group_by(field, year) |>
  summarize(median_n_per_cell = janitor::round_half_up(median(N_per_cell, na.rm = TRUE), 0)) |>
  ungroup()

# Calculate median median n for each field
data_table_2_n_aggregate <- data_table_2_n_long |>
  group_by(field) |>
  summarize(median_median_n_per_cell = median(median_n_per_cell, na.rm = TRUE)) |>
  ungroup()

# Calculate k studies used to calculate median ns
data_table_2_k_long <- data_table_2_filtered |>
  count(field, year, name = "k_studies")

# combine Ns and Ks, reshape, and order field column by aggregate median median n 
data_table_2 <- 
  full_join(data_table_2_n_long, data_table_2_k_long, by = c("field", "year")) |>
  mutate(result = paste0(median_n_per_cell, " (", k_studies, ")")) |>
  select(-median_n_per_cell, -k_studies) |>
  pivot_wider(names_from = year, 
              values_from = result) |>
              #names_prefix = "NF ") |>
  left_join(data_table_2_n_aggregate, by = "field") |>
  mutate(field = fct_reorder(field, median_median_n_per_cell)) |>
  arrange(desc(field)) |>
  select(field, median_median_n_per_cell, 
         `'06`, `'07`, `'08`, `'09`, `'10`, `'11`, 
         `'12`, `'13`, `'14`, `'15`, `'16`, `'17`, 
         `'18`, `'19`, `'20`, `'21`, `'22`)

# print table
data_table_2 |>
  select(field, 
         Aggregate = median_median_n_per_cell, 
         starts_with("'")) |>
         #starts_with("NF")) |>
  kable() |>
  kable_classic(full_width = FALSE)

```

### Figure

```{r}

# Filter out non-social studies published in psych science
# calculate median Ns
# order field column by same used in Table 1
data_figure_2 <- data_table_2_filtered |>
  group_by(field, year) |>
  summarize(median_n_per_cell = janitor::round_half_up(median(N_per_cell, na.rm = TRUE), 0)) |>
  ungroup() |>
  mutate(field = fct_rev(fct_relevel(field, levels(data_table_1$field))))

# plot 
ggplot(data_figure_2, aes(as.factor(year), median_n_per_cell, group = field)) +
  geom_smooth(method = "lm") +
  geom_line() +
  geom_point() +
  scale_color_viridis_d(option = "plasma", begin = 0.1, end = 0.9) +
  theme_classic() +
  ylab("Median sample size (N) per cell") +
  xlab("Year") 

```

### Estimate change in median N over time

```{r fig.height=10, fig.width=6}

data_for_model_2 <- data_figure_2 |>
  mutate(year = as.numeric(str_remove(year, "'")),
         year_recentered = year - 06)

fit_2 <- lm(formula = median_n_per_cell ~ year_recentered,
                data = data_for_model_2)

#check_model(fit_2)
#check_normality(fit_2)

tab_model(fit_2, 
          string.est = "B",
          digits = 1,
          ci.hyphen = ", ")

```

Note that data was re-centered so that the intercept is 2006. 

Predictable violations of assumptions due to the skew in sample sizes mean that results must be interpreted in much caution. No p values are presented as no hypotheses were tested: the purpose of the regression was to provide an illustrative estimate of the change in sample size per year.

#### Combined plot

Probably most useful for publication

```{r}

p_median_n_over_time <- 
  # combine data
  bind_rows(
    data_figure_1 |>
      mutate(type = "Participants per study (all studies)"),
    data_figure_2 |>
      rename(median_n = median_n_per_cell) |>
      mutate(type = "Participants per group (studies with between-subjects comparisons)")
  ) |>
  # plot
  ggplot(aes(as.factor(year), median_n, group = type, color = type)) +
  geom_smooth(method = "lm", alpha = 0.2) +
  geom_line() +
  geom_point() +
  scale_color_viridis_d(option = "viridis", begin = 0.3, end = 0.7,
                        guide = guide_legend(reverse = TRUE)) +
  theme_classic() +
  ylab("Median sample size (N)") +
  xlab("Year") +
  theme(legend.position = "bottom",
        legend.direction = "vertical",
        legend.title = element_blank())

p_median_n_over_time

ggsave("plots/p_median_n_over_time.pdf",
       plot = p_median_n_over_time,
       width = 6,
       height = 5,
       units = "in")

```

## Implied Statistical Power for $\rho$ = .20

#### Table

```{r}

# use median n to calculate power
data_table_3_long <- data_table_2_n_long |>
  #mutate(power = janitor::round_half_up(pwr.r.test(r = .2, sig.level = 0.05, n = median_n_per_cell)$power*100, 0)) |>
  mutate(power = janitor::round_half_up(pwr.t.test(d = .408, sig.level = 0.05, n = median_n_per_cell, type = "two.sample")$power*100, 0)) |>
  select(-median_n_per_cell)

# reshape table, order field column by that used in previous table
data_table_3 <- data_table_3_long |>
  pivot_wider(names_from = year, 
              values_from = power) |>
              #names_prefix = "power ") |>
  mutate(field = fct_relevel(field, levels(data_table_1$field))) |>
  arrange(desc(field)) |>
  select(field, 
         `'06`, `'07`, `'08`, `'09`, `'10`, `'11`, 
         `'12`, `'13`, `'14`, `'15`, `'16`, `'17`, 
         `'18`, `'19`, `'20`, `'21`, `'22`)

# print table
data_table_3 |>
  kable() |>
  kable_classic(full_width = FALSE)

```

#### Figure

```{r}

# order field column by same used in Table 1, then plot
p_power <- data_table_3_long |>
  mutate(field = fct_rev(fct_relevel(field, levels(data_table_1$field)))) |>
  ggplot(aes(as.factor(year), power/100, group = field)) +
  geom_hline(yintercept = .80, linetype = "dotted") +
  geom_smooth(method = "lm", alpha = 0.2, colour = "black") +
  geom_line() +
  geom_point() +
  scale_color_viridis_d(option = "plasma", begin = 0.1, end = 0.9) +
  scale_y_continuous(labels = scales::label_comma(), 
                     breaks = c(0, .2, .4, .6, .8, 1), 
                     limits = c(0,1)) +
  theme_classic() +
  ylab("Power") +
  xlab("Year")

p_power

ggsave("plots/p_power.pdf",
       plot = p_power,
       width = 6,
       height = 4,
       units = "in")

```

#### Estimate change  in power over time

```{r fig.height=10, fig.width=6}

data_for_model_3 <- data_table_3_long |>
  mutate(year = as.numeric(str_remove(year, "'")),
         year_recentered = year - 6,
         power = power/100)

fit_3 <- lm(formula = power ~ year_recentered,
            data = data_for_model_3)

#check_model(fit_3)
#check_normality(fit_3)

tab_model(fit_3, 
          string.est = "B",
          digits = 3,
          ci.hyphen = ", ")

```

Note that data was re-centered so that the intercept is 2006. 

```{r}

predicted_power_2022 <- (0.142 + 0.009*(2022-2006)) # values taken from regression results table

necessary_increase_to_reach_power_.80 <- .80 - predicted_power_2022

years_until_power_.80 <- ceiling(necessary_increase_to_reach_power_.80 / 0.009)

```

If this rate of increase in median sample sizes is maintained, power of at least .80 (Cohen, 1988) in the median IRAP study would be achieved `r years_until_power_.80` years from now, i.e., by `r 2022 + years_until_power_.80`.



# IRAP vs Social Psychology studies using study N (after exclusions)

## Median sample size 

### Table

```{r}

# calculate median N for each field and year
# round using typical half-up rule and not R's weird rounding
data_table_5_n_long <- data_combined_comparison |>
  group_by(field, year) |>
  summarize(median_n = janitor::round_half_up(median(N, na.rm = TRUE), 0)) |>
  ungroup()

# Calculate median median n for each field
data_table_5_n_aggregate <- data_table_5_n_long |>
  group_by(field) |>
  summarize(median_median_n = median(median_n, na.rm = TRUE)) |>
  ungroup()

# Calculate k studies used to calculate median ns
data_table_5_k_long <- data_combined_comparison |>
  count(field, year, name = "k_studies")

# combine Ns and Ks, reshape, and order field column by aggregate median median n 
data_table_5 <- 
  full_join(data_table_5_n_long, data_table_5_k_long, by = c("field", "year")) |>
  mutate(result = paste0(median_n, " (", k_studies, ")")) |>
  select(-median_n, -k_studies) |>
  pivot_wider(names_from = year, 
              values_from = result) |>
              #names_prefix = "NF ") |>
  left_join(data_table_5_n_aggregate, by = "field") |>
  mutate(field = fct_reorder(field, median_median_n)) |>
  arrange(desc(field)) |>
  select(field, median_median_n, 
         `'06`, `'07`, `'08`, `'09`, `'10`, `'11`, 
         `'12`, `'13`, `'14`, `'15`, `'16`, `'17`, 
         `'18`, `'19`, `'20`, `'21`, `'22`)

# print table
data_table_5 |>
  select(field, 
         Aggregate = median_median_n, 
         starts_with("'")) |>
         #starts_with("NF")) |>
  kable() |>
  kable_classic(full_width = FALSE)

```

### Figure

```{r}

# Filter out non-social studies published in psych science
# calculate median Ns
# order field column by same used in Table 1
data_figure_4 <- data_combined_comparison |>
  group_by(field, year) |>
  summarize(median_n = janitor::round_half_up(median(N, na.rm = TRUE), 0)) |>
  ungroup() |>
  mutate(field = fct_rev(fct_relevel(field, levels(data_table_1$field))))

# plot 
p_median_n_over_time_comparison <- 
  ggplot(data_figure_4, aes(as.factor(year), median_n, color = field, group = field)) +
  geom_smooth(method = "lm", alpha = 0.2) +
  geom_line() +
  geom_point() +
  scale_y_continuous(breaks = c(0, 50, 100, 150, 200, 250, 300)) +
  scale_color_viridis_d(option = "viridis", begin = 0.3, end = 0.7) +
  theme_classic() +
  ylab("Median sample size (N) per study") +
  xlab("Year") +
  labs(colour = "Field") +
  theme(legend.position = "bottom",
        legend.direction = "vertical",
        legend.title = element_blank())

p_median_n_over_time_comparison

ggsave("plots/p_median_n_over_time_comparison.pdf",
       plot = p_median_n_over_time_comparison,
       width = 6,
       height = 5,
       units = "in")

```

### Test differences in change in median N over time

```{r fig.height=10, fig.width=6}

data_for_model_4 <- data_figure_4 |>
  mutate(year = as.numeric(str_remove(year, "'")),
         year_recentered = year - 06,
         field = fct_relevel(field, "IRAP research", "Social Psychology"))

fit_4 <- lm(formula = median_n ~ year_recentered * field,
                data = data_for_model_4)

#check_model(fit_4)
#check_normality(fit_4)

tab_model(fit_4, 
          string.est = "B",
          digits = 1,
          ci.hyphen = ", ")

```

P value of the interaction effect is used to test differences in change in median values over time.

Note that data was re-centered so that the intercept is 2006. 

## Implied Statistical Power for $\rho$ = .20

### Table

```{r}

# use median n to calculate power
data_table_6_long <- data_table_5_n_long |>
  mutate(power = janitor::round_half_up(pwr.r.test(r = .2, sig.level = 0.05, n = median_n)$power*100, 0)) |>
  select(-median_n)

# reshape table, order field column by that used in previous table
data_table_6 <- data_table_6_long |>
  pivot_wider(names_from = year, 
              values_from = power) |>
              #names_prefix = "power ") |>
  mutate(field = fct_relevel(field, levels(data_table_1$field))) |>
  arrange(desc(field)) |>
  select(field, 
         `'06`, `'07`, `'08`, `'09`, `'10`, `'11`, 
         `'12`, `'13`, `'14`, `'15`, `'16`, `'17`, 
         `'18`, `'19`, `'20`, `'21`, `'22`)

# print table
data_table_6 |>
  kable() |>
  kable_classic(full_width = FALSE)

```

### Figure

```{r}

# order field column by same used in Table 1, then plot
p_power_comparison <- data_table_6_long |>
  mutate(field = fct_rev(fct_relevel(field, levels(data_table_1$field)))) |>
  ggplot(aes(as.factor(year), power/100, color = field, group = field)) +
  geom_hline(yintercept = .80, linetype = "dotted") +
  geom_smooth(method = "lm", alpha = 0.2) +
  geom_line() +
  geom_point() +
  scale_color_viridis_d(option = "viridis", begin = 0.3, end = 0.7) +
  theme_classic() +
  ylab("Power") +
  xlab("Year") +
  labs(colour = "field") +
  scale_y_continuous(labels = scales::label_comma(), 
                     breaks = c(0, .2, .4, .6, .8, 1), 
                     limits = c(0,1)) +
  labs(colour = "Field") +
  theme(legend.position = "bottom",
        legend.direction = "vertical",
        legend.title = element_blank())

p_power_comparison

ggsave("plots/p_power_comparison.pdf",
       plot = p_power_comparison,
       width = 6,
       height = 5,
       units = "in")

```

### Test differences in change in power over time

```{r fig.height=10, fig.width=6}

data_for_model_5 <- data_table_6_long |>
  mutate(year = as.numeric(str_remove(year, "'")),
         year_recentered = year - 06,
         power = power/100)

fit_5 <- lm(formula = power ~ year_recentered * field,
            data = data_for_model_5)

#check_model(fit_5)
#check_normality(fit_5)

tab_model(fit_5, 
          string.est = "B",
          digits = 2,
          ci.hyphen = ", ")

```

P value of the interaction effect is used to test differences in change in implied power over time.

Note that data was re-centered so that the intercept is 2006. 



